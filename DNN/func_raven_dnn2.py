
from __future__ import absolute_import, division, print_function
import time
import numpy as np
import pandas as pd
import tensorflow as tf
import math
import sys

from tensorflow import keras

import pathlib

import pandas as pd
import seaborn as sns

from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation

from tensorflow.python.client import device_lib
from keras import backend as K

import matplotlib.pyplot as plt

from keras.utils import plot_model

import func_filters as ff
import func_name_ravenstate as name_ravenstate



class raven_dnn_estimator:
    #--------------------------------------------------------------------------
    # Data ralatives
    
    # Original data, with no generated features
    data_origin = None
    # Raw data, with generated features, but no shuffling
    data_raw = None
    # Original label
    label_origin = None
    
    # data names
    name_data_origin = None
    name_data = None
    name_label = None
    
    # normalized data
    data_normaled = None
    label_normaled = None
    
    # percentage of training set, validation set and test set
    percent_train = None
    percent_vali = None
    percent_test = None
    
    # shuffle seed of the three sets
    shuffle_seed_train = None
    shuffle_seed_vali = None
    shuffle_seed_test = None
    
    # operation matrix(nx2), contains all the operation pairs
    operation_matrix = None
    operation_pool = [1,2,3,4,5,6,7] # Operations that will be chosen by the auto feature generator
    
    # This is the matrix with same lines and index as data, the first column is mean and the second 
    # is std variance, thus to make prediction, the data should be normalized using these two parameters
    # normalized_data = (raw_data - mean) / std_var
    normalize_matrix_data = None
    normalize_matrix_label = None
    
    # Three left side sets
    data_train = None
    data_vali = None
    data_test = None
    
    # Three label sets
    label_train = None
    label_vali = None
    label_test = None
    
    # signal indecating using ravenstate like signal or not. If =1, means feature rate is larger than label rate, this will benefit taking derivative
    # if raven_data_signal=1, then the following two time must be provided to find index 
    raven_data_signal = None
    time_data = None
    time_label = None
    seed_ravenstate_idx = None # this will record the index of ravenstate that is consistent to the label time
    
    #--------------------------------------------------------------------------
    # DNN relatives
    
    # The deep neural network model, generated by Keras
    dnn_model = None
    
    # The loss of the previous traning and current training
    loss_pre = None
    loss_cur = None
    
    # DNN training history provided by keras
    history = None
    loss_decrease_percent = None
    
    # Function to generate test data, and load data to the system
    def test_data_generator(self):
        
        # x,y,z to w----------------------------------------------------------------------------------
#        x = np.linspace(800, 1, 10000)
#        x = np.power(x,1.5)
#        y = np.linspace(1, 200, 10000)
#        #y = np.power(y,3)
#        z = np.linspace(1, 4000000, 10000)  
#        z = np.sqrt(z)
#        
##        x = np.linspace(10, 1, 10000)
##        y = np.linspace(20, 10, 10000)
##        z = np.linspace(1, 20, 10000)  
#
#        label = np.array([x*np.sqrt(y)*z + np.power(x,1.5) * np.log(z)**2 + 100*np.exp(np.sqrt(y))])
##        label = np.array([np.sin(x) * np.cos(y) + np.sin(z)])
##        label = np.array([x * z + y])
#        
#        #label = np.array([x+y+z])
#        data = np.zeros((3,np.size(x)))
#        data[0] = x
#        data[1] = y
#        data[2] = z
#        label_name = ["w"]
#        data_name = ["x" , "y" , "z"]
#        operation_origin = np.int_(np.ones((3,2)) * -1)
        
        #w to x,y,z----------------------------------------------------------------------------------
        x = np.linspace(800, 1, 10000)
        x = np.power(x,1.5)
        y = np.linspace(1, 200, 10000)
        z = np.linspace(1, 4000000, 10000)  
        z = np.sqrt(z)
        
        # Linear Monotonous distribution
#        x = np.linspace(10, 1, 10000)
#        y = np.linspace(10, 20, 10000)
#        z = np.linspace(1, 20, 10000)  
#        
        # Linear Non-monotonous
#        x = np.linspace(800, 1, 10000)
#        y = np.append(np.linspace(1200, 1, 5000), np.linspace(1,1200,5000))
#        z = np.linspace(1, 2000, 10000)  


        data = np.array([x*np.sqrt(y)*z + np.power(x,1.5) * np.log(z)**2 + 100*np.exp(np.sqrt(y))])
#        data = np.array([x + z + y])
#        data = np.array([np.sin(x) * np.cos(y) + np.sin(z)])
        
#        data = np.array([x * y * z])
        #label = np.array([x+y+z])
        label = np.zeros((3,np.size(x)))
        label[0] = x
        label[1] = y
        label[2] = z
        data_name = ["w"]
        label_name = ["x" , "y" , "z"]
        operation_origin = np.int_(np.ones((1,2)) * -1)
        
        #w to x,y,z----------------------------------------------------------------------------------
#        x = np.linspace(800, 1, 10000)
#        x = np.power(x,1.5)
#        y = np.linspace(1, 20000, 10000)
#        z = np.linspace(1, 4000000, 10000)  
#        z = np.sqrt(z)
#        
#        # Linear Monotonous distribution
##        x = np.linspace(10, 1, 10000)
##        y = np.linspace(10, 20, 10000)
##        z = np.linspace(1, 20, 10000)  
##        
#        # Linear Non-monotonous
##        x = np.linspace(800, 1, 10000)
##        y = np.append(np.linspace(1200, 1, 5000), np.linspace(1,1200,5000))
##        z = np.linspace(1, 2000, 10000)  
#
#
##        data = np.array([x*np.sqrt(y)*z + np.power(x,1.5) * np.log(z)**2 + 100*np.exp(np.sqrt(y))])
##        data = np.array([x + z + y])
#        A = np.array([[1,2,3],
#                      [4,6,5],
#                      [8,4,2]])
#        label_mat = np.dot(A,np.array([x,y,z]))
#        
##        data = np.array([x * y * z])
#        #label = np.array([x+y+z])
#        data = np.zeros((3,np.size(x)))
#        label = np.zeros((3,np.size(x)))
#        
#        data[0] = x
#        data[1] = y
#        data[2] = z
#        
#        label[0] = label_mat[0]
#        label[1] = label_mat[1]
#        label[2] = label_mat[2]
#        data_name = ["x" , "y" , "z"]
#        label_name = ["label_1" , "label_2" , "label_3"]
#        operation_origin = np.int_(np.ones((3,2)) * -1)
        
        
        #----------------------------------------------------------------------------------
        folder_name = "data_folder/"
        np.savetxt ( folder_name + "test_data.txt", data )
        np.savetxt ( folder_name + "test_label.txt", label )
        np.savetxt ( folder_name + "test_operation.txt", np.int_(operation_origin))
        
        #[BUG] Currently cannot load string txt file as usable list
#        data_name_file = open("test_data_name.txt" , "w")
#        for content in data_name:
#            data_name_file.write(content + "\n")
#            
#        label_name_file = open("test_label_name.txt" , "w")
#        for content in label_name:
#            label_name_file.write(content + "\n")
        
        # Set initial values for the objects in the class
        self.data_origin = data
        self.data_raw = data
        self.label_origin = label
        self.operation_matrix = operation_origin
        
        self.name_data_origin = data_name
        self.name_data = data_name
        self.name_label = label_name
        
        self.data_normaled = np.zeros(data.shape)
        self.label_normaled = np.zeros(label.shape)
        self.normalize_matrix_data = np.zeros((data.shape[0],2))
        self.normalize_matrix_label = np.zeros((label.shape[0],2))
        
        self.raven_data_signal = 0
        
        print("[RAVEN_DNN]: Using testing data, more details can be found in <func_raven_dnn.py>")
        
        return data, label, operation_origin
    
    # [UNFINISHED] Load data from txt file
    def load_data(self, data = None, label = None, operation_origin = None, data_name = None, label_name = None, raven_data_signal = 0, time_data = None, time_label = None , seed_ravenstate_idx = None):
        folder_name = "data_folder/"
        
        data_file_name = folder_name + "test_data.txt"
        label_file_name = folder_name + "test_label.txt"
        operation_file_name = folder_name + "test_operation.txt"
        
        
        print_dash_line()
        print("[RAVEN_DNN]: Loading data ")
        
        try:
            if data == None:
                print("[RAVEN_DNN]:No data provided, trying to load data from txt file")
                data = np.loadtxt(data_file_name)
                try:
                    test_dimesion = data.shape[1]
                except:
                    data = np.array([data])
            if label == None:
                print("[RAVEN_DNN]:No label provided, trying to load label from txt file")
                label = np.loadtxt(label_file_name)
                try:
                    test_dimesion = label.shape[1]
                except:
                    label = np.array([label])
            if operation_origin == None:
                print("[RAVEN_DNN]:No operation provided, trying to load operation from txt file")
                operation_origin = np.int_(np.loadtxt(operation_file_name))
                try:
                    test_dimesion = operation_origin.shape[1]
                except:
                    operation_origin = np.array([operation_origin])
        except:
            print("[RAVEN_DNN]:ERROR: Loading data from txt failed, please check the folder")
            
        self.raven_data_signal = raven_data_signal
        
        if self.raven_data_signal == 1:
            self.seed_ravenstate_idx = np.int_(seed_ravenstate_idx)
            print("[RAVEN_DNN]: Using RAVEN data, index initialized")
            
        self.data_origin = data
        self.data_raw = data
        self.label_origin = label
        self.operation_matrix = operation_origin
        
        self.name_data_origin = data_name
        self.name_data = data_name
        self.name_label = label_name
        
        self.data_normaled = np.zeros((data.shape[0],label.shape[1]))
        self.label_normaled = np.zeros(label.shape)
        self.normalize_matrix_data = np.zeros((data.shape[0],2))
        self.normalize_matrix_label = np.zeros((label.shape[0],2))
        print("[RAVEN_DNN]: All data loaded")
        
        print_dash_line()
        return None
    
    # Initialize the system, then the system will be ready to train DNN, and add new features will be available
    def init_system(self):
        self.set_percent()
        self.set_shuffle_seed()
        self.generate_data()
        self.normalize_data()
        self.load_dnn_sets()
        self.update_feature_name()
        
        print("[RAVEN_DNN]: Initialization finished, ready to train DNN")
        return None
    
    # Updata data raw from data_origin to data_raw, according to operation matrix
    def generate_data(self):
        # Rearrange the data_raw to fit the size
        self.data_raw = np.zeros((self.data_origin.shape[0], self.data_origin.shape[1]))
        self.init_dnn_sets_shape()
        for index in range(0,self.operation_matrix.shape[0]):
            operation_pair = self.operation_matrix[index]
            operation_object = operation_pair[0]
            operation_type = operation_pair[1]
            
            if operation_type == -1: # Original data, do nothing
                new_line = self.data_origin[index]
            else:
                new_line = self.add_new_feature([operation_pair], arg = [None], show_report = False)
            self.data_raw[index] = new_line
                
    def normalize_data(self):
        # Rearrange the normalize matrix to fit the size
        self.normalize_matrix_data = np.zeros((self.data_raw.shape[0],2))
        self.normalize_matrix_label = np.zeros((self.label_origin.shape[0],2))
        
        if self.raven_data_signal == 0:
            # Normalize data
            for line_index in range(0, self.data_raw.shape[0]):
                data_line_nor, mean, std = self.normalize_line(self.data_raw[line_index])
                self.normalize_matrix_data[line_index] = [mean, std]
                self.data_normaled[line_index] = data_line_nor
                
            # Normalize label
            for line_index in range(0, self.label_origin.shape[0]):
                data_line_nor, mean, std = self.normalize_line(self.label_origin[line_index])
                self.normalize_matrix_label[line_index] = [mean, std]
                self.label_normaled[line_index] = data_line_nor
                
        if self.raven_data_signal == 1:
            # Normalize data
            for line_index in range(0, self.data_raw.shape[0]):
                data_line_nor, mean, std = self.normalize_line(self.data_raw[line_index][self.seed_ravenstate_idx])
                self.normalize_matrix_data[line_index] = [mean, std]
                self.data_normaled[line_index] = data_line_nor
                
            # Normalize label
            for line_index in range(0, self.label_origin.shape[0]):
                label_line_nor, mean, std = self.normalize_line(self.label_origin[line_index])
                self.normalize_matrix_label[line_index] = [mean, std]
                self.label_normaled[line_index] = label_line_nor
        print("[RAVEN_DNN]: Data normalization finished")
        
    
    # Load DNN sets( such as training set, including labels), after this, the system will be ready to train DNN       
    def load_dnn_sets(self):
        #Initialize the shape
        self.data_train = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_train)))
        self.data_vali = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_vali)))
        self.data_test = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_test)))
        #Initialize the shape
        self.label_train = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_train)))
        self.label_vali = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_vali)))
        self.label_test = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_test)))
        
        for line_index in range(0, self.data_normaled.shape[0]):
            data_line = self.data_normaled[line_index]
            self.data_train[line_index] = data_line[self.shuffle_seed_train]
            self.data_vali[line_index] = data_line[self.shuffle_seed_vali]
            self.data_test[line_index] = data_line[self.shuffle_seed_test]
            
        for line_index in range(0, self.label_normaled.shape[0]):
            label_line = self.label_normaled[line_index]
            self.label_train[line_index] = label_line[self.shuffle_seed_train]
            self.label_vali[line_index] = label_line[self.shuffle_seed_vali]
            self.label_test[line_index] = label_line[self.shuffle_seed_test]
            
    def init_dnn_sets_shape(self):
        #Initialize the shape
        self.data_train = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_train)))
        self.data_vali = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_vali)))
        self.data_test = np.zeros((self.data_normaled.shape[0],np.size(self.shuffle_seed_test)))
        #Initialize the shape
        self.label_train = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_train)))
        self.label_vali = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_vali)))
        self.label_test = np.zeros((self.label_normaled.shape[0],np.size(self.shuffle_seed_test)))
        
        return None
        
    
    # set operation pool            
    def set_operation_pool(self, operation_pool):
        self.operation_pool = operation_pool
        return None
    
    # Generate new feature, one line at a time
    def generate_new_feature_line(self, operation_pair, arg = [None]):
            operation_object = int(operation_pair[0])
            operation_type = int(operation_pair[1])
            
            if operation_type == -1: # Original data, do nothing
                return None
            
            if operation_type == 1: # take derivative
                if arg ==[None]:
                    new_line = np.gradient(self.data_raw[operation_object], 0.001 ,edge_order = 2)
                elif self.raven_data_signal == 1:
                    new_line = ff.mov_avr_derivative(self.data_raw[operation_object], 0.001 , window_size = 501)
                
            elif operation_type == 2: # power
                origin_object = operation_object
                if self.operation_matrix[origin_object][0] == -1:
                    new_line = self.data_raw[operation_object] * self.data_raw[origin_object]
                else:
                    while int(self.operation_matrix[int(self.operation_matrix[origin_object][0])][1]) == self.operation_matrix[operation_object][1]:
                        origin_object = int(self.operation_matrix[origin_object][0])
                    new_line = self.data_raw[operation_object] * self.data_raw[origin_object]
                
            elif operation_type == 3: #log
                if self.data_raw[operation_object].min() > 0:
                    new_line = np.log(self.data_raw[operation_object])
                else:
                    new_line = np.log((self.data_raw[operation_object] - self.data_raw[operation_object].min() + 1))
            
            elif operation_type == 4: # Sin
                new_line = np.sin(self.data_raw[operation_object])
                
            elif operation_type == 5: # Cos
                new_line = np.cos(self.data_raw[operation_object])
                
            elif operation_type == 6: # Intergral
                new_line = np.zeros(self.data_raw[operation_object].shape)
                for inter_lenth in range(0, self.data_raw[operation_object].shape[0]):
                  new_line[inter_lenth] = np.trapz(self.data_raw[operation_object][0:inter_lenth], x = arg[0], dx = 0.001)
            
            elif operation_type == 7: # Square root
                if self.data_raw[operation_object].min() > 0:
                    new_line = np.sqrt(self.data_raw[operation_object])
                else:
                    new_line = np.sqrt((self.data_raw[operation_object] - self.data_raw[operation_object].min() + 0.0000001))
                    
            elif operation_type == 8: # Flag
                mean = arg[0]
                std = 10*arg[1]
                constant_para = arg[2]
                new_line = 1/(std*np.sqrt(2*math.pi)) * np.exp(-((self.data_raw[operation_object]-mean)**2/(2*std**2)))
                new_line = new_line + np.mean(new_line) * constant_para
                
            else:
                print("[RAVEN_DNN]ERROR:Unknown operation type")
                sys.exit()
            
            return new_line
    
    def get_name_data_origin(self):
        name_data_origin = self.name_data_origin
        return name_data_origin
    
        # Used to update 
    def update_feature_name(self):
        name_data_origin = self.get_name_data_origin()
        self.name_data = name_data_origin
        self.operation_matrix = np.int_(self.operation_matrix) # Make sure all the elements are int type
        for line_index in range(0, self.operation_matrix.shape[0]):
            if self.operation_matrix[line_index][0] == -1:
                continue
            else:
                if self.operation_matrix[line_index][1] == 1:
                    new_name = "Derivative of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 2:
                    new_name = "Power of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 3:
                    new_name = "Log of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 4:
                    new_name = "Sin of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 5:
                    new_name = "Cos of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 6:
                    new_name = "Integral of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 7:
                    new_name = "Sqrt of " + self.name_data[self.operation_matrix[line_index][0]]
                elif self.operation_matrix[line_index][1] == 8:
                    new_name = "Flag of " + self.name_data[self.operation_matrix[line_index][0]]
                else:
                    print("[RAVEN_DNN]ERROR:Unkonw operation type")
                    sys.exit()
                try:
                    self.name_data[line_index] = new_name
                except:
                    self.name_data.append(new_name)
                    
    def info_operation(self):
        print_dash_line()
        print("[RAVEN_DNN]: Operations List: ")
        index = 0
        self.operation_matrix = np.int_(self.operation_matrix)
        for operation in self.operation_matrix:
            if operation[1] == -1:
                print("index: " + str(index) + " | " + "Object: None | Operation: None       | " + "Name: Original " + self.name_data[index])
            elif operation[1] == 1:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Derivative | Name: " + self.name_data[index])
            elif operation[1] == 2:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Power      | Name: " + self.name_data[index])
            elif operation[1] == 3:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Log        | Name: " + self.name_data[index])
            elif operation[1] == 4:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Sin        | Name: " + self.name_data[index])
            elif operation[1] == 5:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Cos        | Name: " + self.name_data[index])
            elif operation[1] == 6:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Integral   | Name: " + self.name_data[index])
            elif operation[1] == 7:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Sqrt       | Name: " + self.name_data[index])
            elif operation[1] == 8:
                print("index: " + str(index) + " | " + "Object: " + str(operation[0]) + "    | " + "Operation: Flag       | Name: " + self.name_data[index])

            else:
                print("[RAVEN_DNN]: Unknown operation type:" + str(operation[1]))
                sys.exit()
            index = index +1
        print_dash_line()
        
        
    def set_percent(self, train_pct = 0.6, vali_pct = 0.2, test_pct = 0.2):
        if (train_pct + vali_pct + test_pct) > 1.0:
           print("[RAVEN_DNN]ERROR:Percentage sum must be less than 1")
           sys.exit()
        self.percent_train = train_pct
        self.percent_vali = vali_pct
        self.percent_test = test_pct
        return
    
    def set_shuffle_seed(self):
        size_total = np.size(self.label_origin[0])
        shuffle_poor = np.arange(size_total)
        np.random.shuffle(shuffle_poor)
        
        size_train = int(size_total * self.percent_train)
        size_vali = int(size_total * self.percent_vali)
        size_test = int(size_total * self.percent_test)
        
        self.shuffle_seed_train = shuffle_poor[0 : size_train]
        self.shuffle_seed_vali = shuffle_poor[size_train : size_train+size_vali]
        self.shuffle_seed_test = shuffle_poor[size_train+size_vali : size_train+size_vali+size_test]
        
        print("[RAVEN_DNN]: Shuffle seed has been set")
        return
    
    def normalize_line(self, data_line):
        mean = np.mean(data_line)
        std = np.std(data_line)     
        if std == 0:
            print("[RAVEN_DNN]Warning: std is 0")
        data_line_nor = (data_line - mean)/ std
        
        return data_line_nor, mean, std
    

                    
                    
    # Generate new features, this will automatically change everthing including training set and so on
    # After this, the data should be ready to train the DNN
    # Input: operation (n,2) array-like, column 0: object, column 1: operation type, when the input is multiple, the argument is not allowed
    # Notice: If there is only one line in operation, it should be like [[5,3]] to meet type requirement
    def add_new_feature(self, operation, arg = [None], show_report = True):
        
        iter_counter = 0
        for operation_pair in operation:
            # First, update data_raw
            new_line = self.generate_new_feature_line(operation_pair, arg = arg)
            new_line_raw = new_line
            self.data_raw = np.append(self.data_raw,[new_line], axis=0)
            
            # Next, update data_normaled and normalize_data_matrix
            new_line_nor, mean , std = self.normalize_line(new_line[self.seed_ravenstate_idx])
            self.normalize_matrix_data = np.append(self.normalize_matrix_data, [[mean, std]], axis = 0)
            self.data_normaled = np.append(self.data_normaled, [new_line_nor], axis = 0)
            
            # Update the operation matrix
            self.operation_matrix = np.append(self.operation_matrix, [operation_pair], axis = 0)
            
            # Finally, shuffle data and set up the three sets for DNN
            self.data_train = np.append(self.data_train, [new_line_nor[self.shuffle_seed_train]], axis = 0)
            self.data_vali = np.append(self.data_vali, [new_line_nor[self.shuffle_seed_vali]], axis = 0)
            self.data_test = np.append(self.data_test, [new_line_nor[self.shuffle_seed_test]], axis = 0)
            
            iter_counter = iter_counter + 1
            self.update_feature_name()
            if show_report == True:
                print("[RAVEN_DNN]: New feature added -- " + self.name_data[-1])
        return new_line_raw
            
            
            
    def delete_new_feature(self, show_report = True):
        if show_report == True:
            print("[RAVEN_DNN]: New feature deleted -- " + self.name_data[-1])
        self.data_raw = np.delete(self.data_raw, -1, axis=0)
        self.normalize_matrix_data = np.delete(self.normalize_matrix_data, -1, axis=0)
        self.data_normaled = np.delete(self.data_normaled, -1, axis=0)
        self.operation_matrix = np.delete(self.operation_matrix, -1, axis=0)
        self.data_train = np.delete(self.data_train, -1, axis=0)
        self.data_vali = np.delete(self.data_vali, -1, axis=0)
        self.data_test = np.delete(self.data_test, -1, axis=0)
        
        self.update_feature_name()
        
        return None

        
    def info_size(self):
        print_dash_line()
        print("[RAVEN_DNN]: Information: Size")
        print_line()
        print("Raw data size: "+ str(self.data_raw.shape))
        print_line()
        print("Training set size: " + str(self.data_train.shape))
        print("Validation set size: " + str(self.data_vali.shape))
        print("Test set size: " + str(self.data_test.shape))
        print_line()
        print("Training label size: " + str(self.label_train.shape))
        print("Validation label size: " + str(self.label_vali.shape))
        print("Test label size: " + str(self.label_test.shape))
        print_line()
        print("Operation matrix size: " + str(self.operation_matrix.shape))
        print("Normalization matrix size: " + str(self.normalize_matrix_data.shape) + "  " + str(self.normalize_matrix_label.shape))
        
        print_dash_line()
        
    # Show the first several sets of the raw data and original labels
    def info_head(self, size = 10, out_fmt = '%.5g'):
        
        print_dash_line()
        
        print("[RAVEN_DNN]: Show Heads:")
        print_line()
        print("Raw data:")
        print(self.data_raw[:,0:size])
        print_line()
        
        print("Original label: ")
        print(self.label_origin[:,0:size])
        print_line()
        
        print("Training data")
        print(self.data_train[:,0:size])
        print_line()
        
        print("Validation data")
        print(self.data_vali[:,0:size])
        print_line()
        
        print("Test data")
        print(self.data_test[:,0:size])
        print_line()
        
        print("Label train")
        print(self.label_train[:,0:size])
        print_line()
        
        print("Label validation")
        print(self.label_vali[:,0:size])
        print_line()
        
        print("Label test")
        print(self.label_test[:,0:size])
        print_line()
        
        print("Data normalization matrix")
        print(self.normalize_matrix_data)
        print_line()
        
        print("Label normalization matrix")
        print(self.normalize_matrix_label)
        
        print_dash_line()
        
        
    def info_data_raw(self, out_fmt = '%.5g'):
        print_dash_line()
        print("[RAVEN_DNN]: Information: data_raw")
        for line_index in range(0, self.data_raw.shape[0]):
            print_line()
            print("Index: " + str(out_fmt % line_index) + " Name: " + self.name_data[line_index])
            print("[Mean]: " + str(out_fmt % np.mean(self.data_raw[line_index])) + " [Std]: " + str(out_fmt % np.std(self.data_raw[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.data_raw[line_index])) + " [Min]: " + str(out_fmt % np.min(self.data_raw[line_index])))
            
        print_dash_line()
            
        
        return None
    
    def info_data_sets(self, out_fmt = '%.5g'):
        print_dash_line()
        
        print("[RAVEN_DNN]: Information: Data Sets")
        print(" ")
        print("Features:")
        for line_index in range(self.data_raw.shape[0]):
            print_line()
            print("Index: " + str(line_index) + " Name: " + self.name_data[line_index])
            print("Training Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.data_train[line_index])) + " [Std]: " + str(out_fmt % np.std(self.data_train[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.data_train[line_index])) + " [Min]: " + str(out_fmt % np.min(self.data_train[line_index])))
            
            print("Validation Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.data_vali[line_index])) + " [Std]: " + str(out_fmt % np.std(self.data_vali[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.data_vali[line_index])) + " [Min]: " + str(out_fmt % np.min(self.data_vali[line_index])))
            
            print("Training Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.data_test[line_index])) + " [Std]: " + str(out_fmt % np.std(self.data_test[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.data_test[line_index])) + " [Min]: " + str(out_fmt % np.min(self.data_test[line_index])))
        
        print_line()
        print(" ")
        print("Labels: ")
        for line_index in range(self.label_origin.shape[0]):
            print_line()
            print("Index: " + str(line_index) + " Name: " + self.name_label[line_index])
            print("Training Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.label_train[line_index])) + " [Std]: " + str(out_fmt % np.std(self.label_train[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.label_train[line_index])) + " [Min]: " + str(out_fmt % np.min(self.label_train[line_index])))
            
            print("Validation Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.label_vali[line_index])) + " [Std]: " + str(out_fmt % np.std(self.label_vali[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.label_vali[line_index])) + " [Min]: " + str(out_fmt % np.min(self.label_vali[line_index])))
            
            print("Training Set:")
            print("[Mean]: " + str(out_fmt % np.mean(self.label_test[line_index])) + " [Std]: " + str(out_fmt % np.std(self.label_test[line_index])))
            print("[Max]: " + str(out_fmt % np.max(self.label_test[line_index])) + " [Min]: " + str(out_fmt % np.min(self.label_test[line_index])))
        

        print_dash_line()     
    
    # Show loss decrease percent
    def info_loss_decrease_percent(self, out_fmt = '%.5g'):
        self.update_feature_name()
        print_dash_line()
        print("[RAVEN_DNN]: Information: Loss decrease by features:")
        line_index = 0
        for percent in self.loss_decrease_percent:
            feature_name = self.name_data[line_index]
            print("  Percentage: " + str(out_fmt % percent) + "% | Feature Name: " + feature_name)
            line_index = line_index + 1
        
        
        print_dash_line()
                    
#------------------------------------------------------------------------------------------------
    # DNN part
    
    # Initialize DNN model
    # layers_matrix = [[0, 10, ""]], excluding the input and output layer
    def dnn_model_init(self, layers_matrix, learning_rate = 0.001, regularize_rate = 0.01 ):
        # Initialize a blank DNN model
        self.dnn_model = keras.Sequential()
        
        kernel_initializer = keras.initializers.glorot_normal(seed = 1)
        
        # Define leaky RELU
        
        # Input layer
        input_layer = layers.Dense(10, 
                                     activation='relu', 
                                     use_bias=True, 
                                     kernel_initializer=kernel_initializer, 
                                     bias_initializer='zeros', 
                                     kernel_regularizer=keras.regularizers.l1(regularize_rate), 
                                     bias_regularizer=keras.regularizers.l1(regularize_rate), 
                                     activity_regularizer=None, 
                                     kernel_constraint=None, 
                                     bias_constraint=None,
                                     input_shape=[self.data_train.shape[0]])
        self.dnn_model.add(input_layer)
        
        # Hidden Layer
        for index, size in layers_matrix:
            kernel_initializer = keras.initializers.glorot_normal(seed = index + 2)
            new_layer = layers.Dense(size, 
                                     activation='relu', 
                                     use_bias=True, 
                                     kernel_initializer=kernel_initializer, 
                                     bias_initializer='zeros', 
                                     kernel_regularizer=keras.regularizers.l1(regularize_rate), 
                                     bias_regularizer=keras.regularizers.l1(regularize_rate), 
                                     activity_regularizer=None, 
                                     kernel_constraint=None, 
                                     bias_constraint=None)
            
            self.dnn_model.add(new_layer)
        
        # Output layer
        kernel_initializer = keras.initializers.glorot_normal(seed = index + 10)
        out_layer = layers.Dense(self.label_train.shape[0],
                                 activation=None, 
                                 use_bias=True, 
                                 kernel_initializer=kernel_initializer, 
                                 bias_initializer='zeros', 
                                 kernel_regularizer=keras.regularizers.l1(regularize_rate), 
                                 bias_regularizer=keras.regularizers.l1(regularize_rate), 
                                 activity_regularizer=None, 
                                 kernel_constraint=None, 
                                 bias_constraint=None )
        self.dnn_model.add(out_layer)
        
        # Set optimizer
        optimizer = keras.optimizers.RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)
        
        # Compile the DNN model
        self.dnn_model.compile(loss='mse',
                     optimizer=optimizer,
                     metrics=['mae', 'mse'])
        
    # Training DNN
    def dnn_train(self, EPOCHS = 100, batch_size = 2000, show_vali_report = True ,show_plot = False):
        class PrintDot(keras.callbacks.Callback):
          def on_epoch_end(self, epoch, logs):
            if epoch % 100 == 0: print('')
            print('.', end='')
        
        # Set early stop
        callback_earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=100, 
                                      verbose=0, mode='min', baseline=None)
        
        EPOCHS = EPOCHS
        
        self.history = self.dnn_model.fit(
          self.data_train.T, self.label_train.T,
          epochs=EPOCHS, batch_size= batch_size, 
          validation_data=(self.data_vali.T, self.label_vali.T), 
          verbose=0,
          callbacks = [callback_earlystop])
        
        hist = pd.DataFrame(self.history.history)
        hist['epoch'] = self.history.epoch
        hist.tail()
        
        if show_plot == True:
            plot_history(self.history, hist)
        
        loss, mae, mse = self.dnn_model.evaluate(self.data_vali.T, self.label_vali.T, verbose=0)
        
        if show_vali_report == True:
            print("[RAVEN_DNN]: Validation set Mean Abs Error:" + str(mae))
        
        return mae
       
    # Interative the training, with automatic adding features    
    def dnn_iter_train(self, 
                       layers_matrix = [[1,20],[2,15],[3,10]],
                       learning_rate = 0.001,
                       regularize_rate = 0.01,
                       EPOCHS = 100, 
                       batch_size = 2000,
                       dropping_threshold = 0.05,
                       max_added_features = 5, 
                       max_iteration = 10,
                       show_plot = False):
        
        print_dash_line()
        print("[RAVEN_DNN]: Iterative training and feature generating begin")
        
        iteration_counter = 0
        line_index = 0
        added_features = 0
        
        self.dnn_model_init(layers_matrix=layers_matrix, 
                            learning_rate=learning_rate, 
                            regularize_rate=regularize_rate)
        
        self.loss_cur = self.dnn_train(EPOCHS=EPOCHS , batch_size =batch_size, show_plot=show_plot)
        loss_pre = self.loss_cur
        self.loss_pre = loss_pre
        
        # initialize loss_decrease_percent
        self.loss_decrease_percent = np.zeros(self.data_origin.shape[0])
        
        while (iteration_counter < max_iteration) & (added_features < max_added_features):
            
            if line_index > (self.data_raw.shape[0] - 1):
                print("[RAVEN_DNN]: No new feature addable, training completed")
                break
                
            for operation_type in self.operation_pool:
                print_line()
                print("[RAVEN_DNN]: New iteration: " + str(iteration_counter))
        
                self.add_new_feature([[line_index, operation_type]])

                self.dnn_model_init(layers_matrix,
                                    learning_rate=learning_rate, 
                                    regularize_rate=regularize_rate)
                self.loss_cur = self.dnn_train(EPOCHS=EPOCHS , batch_size =batch_size , show_plot = show_plot)
                
                # if the loss is decreased by some value, keep the new feature, 
                # if not discard the new feature
                print("[RAVEN_DNN]: MAE change persent: " + str((self.loss_cur - self.loss_pre)/ self.loss_pre * 100) + "%")
                if ((self.loss_cur - self.loss_pre)/ self.loss_pre) > (-dropping_threshold):
                    print("[RAVEN_DNN]: Unuseful feature, discard")
                    self.delete_new_feature()
                else:
                    added_features = added_features + 1
                    print("[RAVEN_DNN]: Useful feature, added. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
                    self.loss_decrease_percent = np.append(self.loss_decrease_percent, (self.loss_cur - self.loss_pre)/ self.loss_pre * 100)
                    loss_pre = self.loss_cur
                    self.loss_pre = loss_pre
                    
                    
                iteration_counter = iteration_counter + 1
                if iteration_counter >= max_iteration:
                    break
            
            line_index = line_index + 1
        
        print_line()
        print("[RAVEN_DNN]: Training completed")
        print_line()
        
        try:
          loss, mae, mse = self.dnn_model.evaluate(self.data_test.T, self.label_test.T, verbose=0)
          print("[RAVEN_DNN]: ***Test set Mean Abs Error***:" + str(mae))
        except:
          self.add_new_feature([[line_index - 1, operation_type]], show_report = False)
          loss, mae, mse = self.dnn_model.evaluate(self.data_test.T, self.label_test.T, verbose=0)
          print("[RAVEN_DNN]: ***Test set Mean Abs Error***:" + str(mae))
          self.delete_new_feature(show_report = False)
          
        self.dnn_model_init(layers_matrix,
                            learning_rate=learning_rate, 
                            regularize_rate=regularize_rate)# Run training again to prevent input size error
        self.dnn_train(EPOCHS=EPOCHS , batch_size =batch_size, show_vali_report = False) # Run training again to prevent input size error
        self.info_operation()
        
        self.info_loss_decrease_percent()
        print_dash_line()
        
        return None
        
    def dnn_make_prediction(self, data_input = None, output_truth = None):
        
        print_dash_line()
        print("[RAVEN_DNN]: Prediction:")
        
        if data_input == None:
            print("[RAVEN_DNN]: No input provided, using raw data")
            if self.raven_data_signal == 0:
                data_input = self.data_raw
            elif self.raven_data_signal == 1:
                toggled_seed_ravenstate = self.seed_ravenstate_idx[range(0,self.seed_ravenstate_idx.size,20)]
                data_input = self.data_raw[:,[toggled_seed_ravenstate]]
        if output_truth == None:
            print("[RAVEN_DNN]: No ground truth provided, using original label")
            output_truth = self.label_origin[:,[range(0,self.label_origin.shape[1],20)]]
        data_input = np.squeeze(data_input)
        output_truth = np.squeeze(output_truth)
        # First, normalize the data
        input_nor = np.zeros(data_input.shape)
        line_index = 0
        for line_raw in data_input:
            input_nor[line_index] = (data_input[line_index] - self.normalize_matrix_data[line_index][0]) / self.normalize_matrix_data[line_index][1]
            line_index = line_index + 1
            
        # Model prediction
        out_put_nor = self.dnn_model.predict(input_nor.T)
        out_put_nor = out_put_nor.T
        out_put = np.zeros(out_put_nor.shape)
        
        # [test]
#        print("|||||||||||||||||||||||||||||||||||||||||||||")
#        print(out_put_nor.shape)
#        print(self.normalize_matrix_label.shape)
        line_index = 0
        for line_out_put_nor in out_put_nor:
            out_put[line_index] = line_out_put_nor * self.normalize_matrix_label[line_index][1] + self.normalize_matrix_label[line_index][0]
            line_index = line_index + 1
            

        
        # Plot the result:
        line_index = 0
        for out_put_line in out_put:
            plt.figure()
            plt.title('Comparison between Prediction and Truth')
            plt.xlabel('index')
            plt.ylabel(self.name_label[line_index])
            plt.plot(out_put_line,
                     label='Prediction')
            plt.plot(output_truth[line_index],"r--",
                     label = 'Truth')
            plt.legend()
            line_index = line_index + 1
            
        print_dash_line()
        
        return out_put
    
    def dnn_plot_features(self):
        
        line_index = 0
        for feature in self.data_raw:
            plt.figure()
            plt.title('Feature:' + self.name_data[line_index] + ' | Contribution: ' +str(self.loss_decrease_percent[line_index]))
            plt.xlabel('index')
            plt.ylabel('Value')
            plt.plot(feature)
            line_index = line_index + 1

    # Find flag
    def dnn_error_flag(self, data_input = None, output_truth = None):
        print_dash_line()
        print("[RAVEN_DNN]: Error Flag:")
        
        if data_input == None:
            print("[RAVEN_DNN]: No input provided, using raw data")
            data_input = self.data_raw
        if output_truth == None:
            print("[RAVEN_DNN]: No ground truth provided, using original label")
            output_truth = self.label_origin
        # First, normalize the data
        input_nor = np.zeros(data_input.shape)
        line_index = 0
        for line_raw in data_input:
            input_nor[line_index] = (data_input[line_index] - self.normalize_matrix_data[line_index][0]) / self.normalize_matrix_data[line_index][1]
            line_index = line_index + 1
            
        # Model prediction
        out_put_nor = self.dnn_model.predict(input_nor.T)
        out_put_nor = out_put_nor.T
        out_put = np.zeros(out_put_nor.shape)
        
        # [test]
#        print("|||||||||||||||||||||||||||||||||||||||||||||")
#        print(out_put_nor.shape)
#        print(self.normalize_matrix_label.shape)
        line_index = 0
        for line_out_put_nor in out_put_nor:
            out_put[line_index] = line_out_put_nor * self.normalize_matrix_label[line_index][1] + self.normalize_matrix_label[line_index][0]
            line_index = line_index + 1
            

        
        # Plot the result:
        line_index = 0
        for out_put_line in out_put:
            error = np.abs(out_put_line - output_truth[line_index])
#            mean_error = (self.label_origin[0].dot(error))/np.mean(error)
            mean_error = self.data_raw[0][np.argmax(error)]
            std = np.std(error)
            line_index = line_index + 1
            
            # [test]
            plt.figure()
            plt.xlabel('w')
            plt.ylabel('Error_Flag')
            plt.plot(self.label_origin[0], error, 'r--',label='Real Error')
            plt.legend()
            # [test]
            plt.xlabel('w')
            plt.ylabel('Error_Flag')
            gaussian_error = 1/(std*np.sqrt(2*math.pi)) * np.exp(-((self.data_raw[0]-mean_error)**2/(2*std**2)))
            gaussian_error = gaussian_error + np.mean(error)/np.max(error) * np.max(gaussian_error)
            gaussian_error = gaussian_error/np.max(gaussian_error) * np.max(error)
            plt.plot(self.label_origin[0], gaussian_error, label='Gaussian Estimated Error')
            plt.legend()
            print("Mean: " + str(mean_error))
            print("Std: " + str(std))
            print("Constant para" + str(np.mean(error)/np.max(error)))
            
        print_dash_line()
        
        return out_put
        
        
    # Plot mdeol
    def dnn_plot_model(self, file_name = 'plot_raven_dnn_model.png'):
        plot_model(self.dnn_model, to_file = file_name, 
                   show_shapes=True, 
                   show_layer_names=True, 
                   rankdir='TB')
        
    def dnn_save_model(self, folder_name = 'raven_dnn_model/'):
        
        self.dnn_model.save(folder_name + 'model_raven_dnn.h5') # save dnn model
        np.savetxt(folder_name + 'operation_matrix.txt', self.operation_matrix)
        
        print_dash_line()
        print("[RAVEN_DNN]: DNN model saved --- Folder Name: " + folder_name)
        print_dash_line()
        
    def dnn_load_model(self, folder_name = 'raven_dnn_model/'):
        print_dash_line()
        self.dnn_model = keras.models.load_model(folder_name + 'model_raven_dnn.h5')
        self.operation_matrix = np.loadtxt(folder_name + 'operation_matrix.txt')
        
#        self.data_normaled = np.zeros(self.data.shape)
#        self.label_normaled = np.zeros(label.shape)
#        self.normalize_matrix_data = np.zeros((data.shape[0],2))
#        self.normalize_matrix_label = np.zeros((label.shape[0],2))
        
        print("[RAVEN_DNN]: DNN model loaded --- Folder Name: " + folder_name)
        print_dash_line()
        
    # Check GPU available
    def check_gpu(self):
        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
        print(device_lib.list_local_devices())
        K.tensorflow_backend._get_available_gpus()
        

# ------------------------------------------------------------------------------------------------
# Normal functions        
        
def print_line():            
    print("_____________________________________________")
    return None

def print_dash_line():
    print("-----------------------------------------------------")
    return None
        
def plot_history(history, hist):
          plt.figure(1)
          plt.xlabel('Epoch')
          plt.ylabel('Mean Abs Error [MPG]')
          plt.plot(hist['epoch'], hist['mean_absolute_error'],
                   label='Train Error')
          plt.plot(hist['epoch'], hist['val_mean_absolute_error'],
                   label = 'Val Error')
          plt.legend()
          plt.ylim([0,1])
          
          plt.figure(2)
          plt.xlabel('Epoch')
          plt.ylabel('Mean Square Error [$MPG^2$]')
          plt.plot(hist['epoch'], hist['mean_squared_error'],
                   label='Train Error')
          plt.plot(hist['epoch'], hist['val_mean_squared_error'],
                   label = 'Val Error')
          plt.legend()
          plt.ylim([0,2])
          
# This is a function to find the nearest value 
def find_nearest(array,value):
    idx = (np.abs(array-value)).argmin()
    return idx
   
                    

    
    